In this report we have tried to provide insights on how the quality of research software could be improved from several different points of view, as well as providing practical recommendations.

We avoided letting the professional views of the authors contributing to this document affect its objectivity. Indeed, each of us have had our own experience on Software development and/or operating software and services, which would not necessarily be representative or general enough for all users and situations.

To overcome this problem, we conducted a systematic and thorough survey of the existing literature according to the keywords, title, and field of the articles. The list was further processed to exclude non-suitable articles (for example  those not actually discussing about quality aspects, among other criteria). Finally, we ended up with a set of relevant articles that were included in our study, which led to a classification into software quality characteristics and software quality attributes and metrics. 

Given that the classification is motivated from what is found in significantly published peer-reviewed articles, this provided an unbiased list of characteristics, which we further classified into significant attributes and metrics. We summarised the list of attributed and metrics in Appendix~\ref{appendix_qa}, where each entry contains our own proposed codename, its name in the source reference, the associated characteristics, its definition, its context of use, and a reference to the source article for tracking and proper citation.

The survey of the broad existing literature and the classification took a large time and effort, but we are convinced that it was the only proper way to proceed in order to describe the landscape of research software and, eventually, propose recommendations.

In the Introduction section of the document, we tried first to define what research software. Our study is specific for research software and therefore it was needed to give a definition. We realised that this attempt could probably end up in an endless discussion before reaching an agreement on a precise definition. Therefore, we took the definition for Research Software as from~\cite{gruenpeter_defining_2021}; any software which is linked to a scientific publication, given that this is surely the most important of its characteristics. 

Software systems can be, in general, organised in different ways, one of them being a stack of components and their dependencies. We reviewed the stack upon which software is built, from libraries to complete services and platforms. 

To complete the landscape section, we included a discussion about what could be the expectations depending on the type of Research Software and depending on specific layers of the Software stack. From the first classification, one can clearly notice that the requirements for a team to build a complete services are very different from those of individual researchers who build their own scripts to produce results for a publication. In the second classification, we discussed the different contexts where Software could be considered, for example as a scientific structure or as a domain-specific tool.

The classification on characteristics, attributes, and metrics from the survey, along with the landscaping on Research Software, allowed us to propose practical recommendations.

Given the landscape of different users and scopes of Research Software, we wrote the recommendations at two different levels. The first group are general recommendations for all types of software including, of course, Research Software. In each group, we listed the corresponding quality attributes.

The second group of recommendations are related to what we have called \textit{user stories}, and are recommendations depending on the role of the users. We have considered a user working in a team, a developer working on an open source project and a user developing a service or platform.

As a case of special interest, we added a section specifically about software in production stage, discussing the management of its release cycle and quality attributes related to services and platforms in production.

In order to facilitate understanding, we provide specific examples and use cases where the recommendations could be applied.

From the recommendations, it comes in a natural way the section about the perspectives or expectations of developers, users, and service providers with respect to Research Software. We profiled which kind of developers are typically working with Research Software, as well as its users. Last but not least, we included also the perspectives of service providers with specific examples of platforms and services.

Finally, we discuss about metadata of software and the FAIR principles and its relation with quality. We show examples of existing tools and initiatives to include metadata for software and discuss how this is important. With respect to the FAIR principles, we focus specifically on the FAIR4RS of the Research Software Working Group, and we map most of the FAIR4RS principles with the quality attributes we propose in this work.

The topology of all software is complex, and defining what should be the characteristics and attributes which define what we understand as its \textit{quality} is challenging.

Indeed, not all quality criteria is equally applicable to different types of Research Software or in any context. The landscaping indeed shows this diversity, and we took that into account, when curating our proposed list of characteristics, attributes and metrics. 

Our recommendations also take into account this diversity, completed with actual use case examples.

We hope the classification and recommendations given in this report will be useful to produce better Research Software to all actors involved.
