\miguel{I'm working on this\dots}

In this report we have tried to provide insights on how the quality of research software could be improved from several different points of view, as well as providing practical recommendations.

We avoided letting the professional views of the authors contributing to this document affect its objectivity. Indeed, each of us have had our own experience when operating software and services, which would not necessarily be representative or general enough for all users and situations.

To overcome this problem, we conducted a systematic and thorough survey of the existing literature according to the keywords, title, and field of the articles. The list was further processed to exclude non-suitable articles (for example  those not actually discussing about quality aspects, among other criteria). Finally, we ended up with a set of relevant articles that were included in our study, which led to a classification into software quality characteristics and software quality attributes and metrics. Given that the classification is motivated from what is found in significant published peer-reviewed articles, this provide an unbiased list of characteristics, which we further classified into significant attributes and metrics. We summarised the list of attributed and metrics in Appendix~\ref{appendix_qa}, where each entry contains our own proposed codename, its name in the source reference, the associated characteristics, its definition, its context of use, and a reference to the source article to help tracking.

The survey of the broad existing literature and the classification took a large time and effort, but we are convinced that it was the only proper way to proceed in order to describe the landscape of research software and, eventually, propose recommendations.

In the Landscaping section of the article we tried first to define what research software. Our study is specific for research software and therefore it was needed to give a definition. We realised that this attempt could probably end up in an endless discussion before reaching an agreement on a precise definition. Therefore, we defined research software as any software which is linked to a scientific publication, given that this is surely the most important of its characteristics. 

Software systems can be, in general, organised in different ways, one of them being a stack of components and their dependencies. We reviewed the stack upon which software is built, from libraries to complete services and platforms. 

To complete the landscape section, we included a discussion about what could be the expectations depending on the type of research software and depending on specific layers of the software stack. From the first classification one can clearly notice that the requirements for a team to build a complete services and very different from those of individual researchers who build their own scripts to produce results in a publication, for example. In the second classification we discussed the different contexts where software could be considered, for example as a scientific structure or as a domain-specific tool.

The classification on characteristics, attributes, and metrics from the survey, along with the landscaping on research software, allowed us to propose  practical recommendations.

Given the landscape of different users and scopes of research software, we wrote the recommendations at two different levels. The first group are general recommendations for all kind of software including, of course, research software. At each of the groups we list the related quality attributes.

The second group of recommendations are related to what we have called \textit{user stories}, and are recommendations depending on the role of the users. We have considered a user working in a team, a developer working on a project which is specifically open-source, and a user developing a service or platform.
%
In order to facilitate understanding, we provide specific examples and use cases where the recommendations could be applied.

From the recommendations, it comes in a natural way the section about the perspectives or expectations of developers, users, and service providers with respect to research software. We profiled which kind of developers are typically working with research software, as well as its users. Last but not least, we included also the perspectives of service providers, along with specific examples of platforms and services.

Our report also explored the case of software specifically in production stage, discussing the management of its release cycle, and quality attributed related to services and platforms in production. \miguel{If SW in prod in moved inside the Recommendations section, we need to move this paragraph too.}

Finally, we discuss about metadata of software and the FAIR principles and its relation with quality. We show examples of existing tools and initiatives to include metadata for software and discuss how this is important. With respect to the FAIR principles, we focus specifically on the FAIR4RS of the Research Software Working Group, and we relate each of the FAIR4RS principles with the quality attributes we propose in this work.

\miguel{I'm writing the conclusions...}
WIP...
